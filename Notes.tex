\documentclass[main.tex]{subfiles}
\begin{document}
\section{Definitions}
\subsubsection*{Bandit Problem}
- Dilemma to study the Exloration vs Exploitation Dilemma \\
- used in maschine learning - reinfocement learning \\
- used experimentally to  study decision making
\subsubsection*{Uncertainty}
\subsection*{Strategies}
\subsubsection*{Thompson Sampling}
\subsubsection*{Upper Confidence Bound?}
\section{Exploration vs. Exploitation}
In here will be a collection of all papers I have read. Especially to the problem of Exploration vs Exploitation \\
\textbf{\cite{speekenbrink2015uncertainty} Uncertainty and Exploration in a Restless Bandit Problem \\}
- bandit problems --> good for studying exploration vs. Exploitation --> maybe see the other  references for introductions\\
- to determine the optimal decision strategy can  be calculated through dynamic programming / or Gittins index for each arm of the bandit\\


\subsection{directed exploration}
\begin{itemize}
\item \citep{auer2002finite}
\item \citep{gittins1979bandit}
\item \citet{gittins1974dynamic}
\end{itemize}
\subsection{random exploration}
\begin{itemize}
\item \citet{thompson1933likelihood}
\item \citet{bridle1990training}

\end{itemize}
\subsection{Decision strategies? }
\citep{schulz2017putting} -- Putting bandits into context How function learning supports decision making \\

\citep{wilson2014humans} -- Humans use direct and random explorarion tosolve the explore exploit dilemma


\subsection{Combination of both explorations}
\cite{gershman2018uncertainty} -- Uncertainty and Exploration



\section{Uncertainty?}
\section{Reinforcement Learning}
\section{Reaction Time Modeling}


\end{document}